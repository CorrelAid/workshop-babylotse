{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify comments\n",
    "\n",
    "In this notebook we will start with analyzing the comments. We will first identify categories with the help of an LLM, then try to refine the found categories and finally classify all comments of the survey into defined categories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import pickle\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "import data\n",
    "import prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allow wider display of columns\n",
    "# don't truncate the display of columns\n",
    "# pd.set_option(\"display.max_columns\", None)\n",
    "# pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preprocessing and mappint to the city neighborhoods is defined in [data.py](./data.py)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = data.load_data(\"Umfrage DE submissions 2024-07-31 00_25.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Stadtteil.str.title().value_counts().nlargest(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.Region.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df.Region.value_counts().plot(\n",
    "    kind=\"bar\", title=\"Teilnehmende pro Region\", width=0.8, color=\"#0160ad\", alpha=1\n",
    ")\n",
    "\n",
    "plt.xticks(rotation=0)\n",
    "plt.xlabel(\"\")\n",
    "plt.ylim((0, 310))\n",
    "plt.yticks(range(0, 301, 50))\n",
    "# plt.ylabel(\"Anzahl\")\n",
    "ax.bar_label(ax.containers[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA comments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Positive[df.Positive.str.len() < 5].shape[0] / df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Positive[df.Positive.str.len() < 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Negative[df.Negative.str.len() < 5].shape[0] / df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in df.Negative[df.Negative.str.len() < 5]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.Negative.str.len() < 5) & (df.Positive.str.len() < 5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze spam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anything that we could not map to a city neighborhood is treated as SPAM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.Stadtteil == \"SPAM\"].shape[0] / df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.Stadtteil == \"SPAM\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.Stadtteil != \"SPAM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(20)[[\"Positive\", \"Negative\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df[\"Positive\"].str.len() <= 7) & (df[\"Negative\"].str.len() <= 7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df[\"Positive\"].str.len() > 7) | (df[\"Negative\"].str.len() > 7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Positive.sample(10).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Negative.sample(10).to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Engineering for Categories\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we do is to ask GPT for a list of categories the comments belong to. We tried in a first attempt to create two lists, one for positive comments and one for negative comments, as well as creating a hierarchy of categories with main and sub categories, but all these attempts worked less well as the most simple approach to come up with a list of categories independent of the sentiment of the comment. We give the model a few examples of good categories and N samples from the data set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = [\"gpt-3.5-turbo\", \"gpt-4-turbo\", \"gpt-4o-mini\"][-1]\n",
    "temperature = 0\n",
    "df_samples = df[(df[\"Positive\"].str.len() > 15) & (df[\"Negative\"].str.len() > 15)][\n",
    "    [\"Positive\", \"Negative\"]\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    # response_format={\"type\": \"json_object\"},\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": prompt.SYSTEM_PROMPT_CAT_v2,\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt.USER_PROMPT_CAT_v2.format(\n",
    "                comments=\"\\n\".join(\n",
    "                    f\"{i+1}. {c}\"\n",
    "                    for i, c in enumerate(\n",
    "                        df_samples.sample(20).values.flatten().tolist()\n",
    "                    )\n",
    "                )\n",
    "            ),\n",
    "        },\n",
    "    ],\n",
    "    temperature=temperature,\n",
    ")\n",
    "\n",
    "print(response.choices[0].finish_reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"artifacts/response_cat.pkl\", \"wb\") as f:\n",
    "    pickle.dump(response.choices[0].message.content, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improve categories\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After generating the first category list, we are now asking GPT to refine this list step by step by giving it another set of examples and allowing it to modify the categories but not deleting any.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"artifacts/response_cat.pkl\", \"rb\") as f:\n",
    "    categories_str = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [c.strip(\"- \") for c in categories_str.splitlines()]\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = [\"gpt-3.5-turbo\", \"gpt-4-turbo\", \"gpt-4o-mini\"][-1]\n",
    "temperature = 0\n",
    "df_samples = df[(df[\"Positive\"].str.len() > 15) & (df[\"Negative\"].str.len() > 15)][\n",
    "    [\"Positive\", \"Negative\"]\n",
    "]\n",
    "\n",
    "for batch in range(4):\n",
    "    print(\"round \", batch)\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        # response_format={\"type\": \"json_object\"},\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": prompt.SYSTEM_PROMPT_REFINED_v2,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt.USER_PROMPT_REFINED_v2.format(\n",
    "                    comments=\"\\n\".join(\n",
    "                        f\"{i+1}. {c}\"\n",
    "                        for i, c in enumerate(\n",
    "                            df_samples.sample(15).values.flatten().tolist()\n",
    "                        )\n",
    "                    ),\n",
    "                    categories=\"\\n\".join(f\"- {c}\" for c in categories),\n",
    "                ),\n",
    "            },\n",
    "        ],\n",
    "        temperature=temperature,\n",
    "    )\n",
    "\n",
    "    print(response.choices[0].finish_reason)\n",
    "    categories_str = response.choices[0].message.content\n",
    "    categories = [c.strip(\"- \") for c in categories_str.splitlines()]\n",
    "    print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"artifacts/response_refined.pkl\", \"wb\") as f:\n",
    "    pickle.dump(response.choices[0].message.content, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"artifacts/response_refined.pkl\", \"rb\") as f:\n",
    "    categories_refined_str = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_refined = [c.strip(\"- \") for c in categories_refined_str.splitlines()]\n",
    "categories_refined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = [\"gpt-3.5-turbo\", \"gpt-4-turbo\", \"gpt-4o-mini\"][-1]\n",
    "temperature = 0\n",
    "\n",
    "draft_categories = \"\"\"\n",
    "Set 1:\n",
    "- Baby-Friendly Activities\n",
    "- Accessibility and Transportation\n",
    "- Childcare Availability\n",
    "- Community Support and Resources\n",
    "- Green Spaces and Nature\n",
    "- Safety and Cleanliness\n",
    "- Family-Friendly Facilities\n",
    "- Healthcare and Support Services\n",
    "- Social Interaction Opportunities\n",
    "- Educational and Developmental Programs\n",
    "- Public Amenities and Facilities\n",
    "- Availability of Playgrounds and Recreational Areas\n",
    "- Information and Transparency about Services\n",
    "Set 2:\n",
    "- Public Spaces and Playgrounds\n",
    "- Family Support Services\n",
    "- Healthcare and Medical Facilities\n",
    "- Transportation Accessibility\n",
    "- Community Activities and Events\n",
    "- Cleanliness and Safety\n",
    "- Childcare Availability\n",
    "- Indoor Play Areas\n",
    "- Parent Networking Opportunities\n",
    "- Dining Options for Families\n",
    "- Accessibility and Inclusivity\n",
    "- Green Spaces and Nature Access\n",
    "- Family-Friendly Facilities and Amenities\n",
    "- Childcare and Educational Resources\n",
    "- Housing Affordability and Availability\n",
    "Set 3:\n",
    "- Family-Friendly Activities and Events\n",
    "- Healthcare Access and Services\n",
    "- Childcare and Kindergarten Availability\n",
    "- Public Transportation Accessibility\n",
    "- Parks and Green Spaces\n",
    "- Community Support and Resources\n",
    "- Safety and Mobility\n",
    "- CafÃ©s and Social Spaces for Families\n",
    "- Cleanliness and Maintenance of Facilities\n",
    "- Educational and Developmental Programs for Children\n",
    "- Availability of Childcare Resources\n",
    "- Support for Parents and Families\n",
    "- Accessibility and Inclusivity for Families\n",
    "- Bureaucratic Processes and Delays\n",
    "- Infrastructure and Facilities for Families\n",
    "Set 4:\n",
    "- Family Support Services\n",
    "- Playgrounds and Recreational Areas\n",
    "- Accessibility and Transportation\n",
    "- Healthcare and Medical Services\n",
    "- Community Events and Activities\n",
    "- Safety and Cleanliness\n",
    "- Childcare and Early Education\n",
    "- Social Interaction Opportunities\n",
    "- Information and Resource Availability\n",
    "- Environmental Quality and Green Spaces\n",
    "- Availability of Family-Friendly Programs and Services\n",
    "- Family-Friendly Infrastructure and Amenities\n",
    "- Public Transportation and Mobility\n",
    "- Availability of Childcare Facilities\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    # response_format={\"type\": \"json_object\"},\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": prompt.SYSTEM_PROMPT_REFINED_FINAL,\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt.USER_PROMPT_REFINED_FINAL.format(\n",
    "                categories=draft_categories,\n",
    "            ),\n",
    "        },\n",
    "    ],\n",
    "    temperature=temperature,\n",
    ")\n",
    "\n",
    "print(response.choices[0].finish_reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"artifacts/response_final.pkl\", \"wb\") as f:\n",
    "    pickle.dump(response.choices[0].message.content, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"artifacts/response_final.pkl\", \"rb\") as f:\n",
    "    final_categories_str = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_categories = [c.strip(\"- \") for c in final_categories_str.splitlines()]\n",
    "final_categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify comments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After discussing the categories with Babylotse, we decided on the final list of categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.final_categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we have a lot of jobs and don't want to run into API limits, we use the batch API endpoint: https://cookbook.openai.com/examples/batch_processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_job(\n",
    "    custom_id: int, sentiment: str, comment: str, categories: list[str]\n",
    ") -> dict:\n",
    "    return {\n",
    "        \"custom_id\": f\"{custom_id}-{sentiment}\",\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": {\n",
    "            \"model\": \"gpt-4o-mini\",\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": prompt.SYSTEM_PROMPT_CLASSIFY.format(\n",
    "                        categories=\",\".join(categories)\n",
    "                    ),\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": f\"Comment: {comment}\"},\n",
    "            ],\n",
    "            \"temperature\": 0,\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "def create_files(df: pd.DataFrame, filename: str) -> list[str]:\n",
    "    indices = df.index\n",
    "    files = []\n",
    "\n",
    "    for i, batch in enumerate(np.array_split(indices, math.ceil(len(indices) / 50))):\n",
    "        filename_ = f\"batch/{filename}_batch_{i+1}.json\"\n",
    "        files.append(filename_)\n",
    "        with open(filename_, \"w\") as f:\n",
    "            for row in df.loc[batch, [\"Positive\", \"Negative\"]].itertuples(index=True):\n",
    "                f.write(\n",
    "                    json.dumps(\n",
    "                        create_job(\n",
    "                            row.Index, \"Positive\", row.Positive, data.final_categories\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "                f.write(\"\\n\")\n",
    "                f.write(\n",
    "                    json.dumps(\n",
    "                        create_job(\n",
    "                            row.Index, \"Negative\", row.Negative, data.final_categories\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "                f.write(\"\\n\")\n",
    "\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = create_files(df, \"batchinput\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the `client.files.create` endpoint to upload our batch files, which is necessary to start jobs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_files = []\n",
    "for file in files:\n",
    "    batch_input_file = client.files.create(\n",
    "        file=open(file, \"rb\"),\n",
    "        purpose=\"batch\",\n",
    "    )\n",
    "    batch_files.append(batch_input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_files[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With each uploaded file, we have a file_id that can be used to start a job with the `client.batches.create` endpoint.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_jobs = []\n",
    "for i, batch_file in enumerate(batch_files):\n",
    "    batch_input_file_id = batch_file.id\n",
    "\n",
    "    batch_job = client.batches.create(\n",
    "        input_file_id=batch_input_file_id,\n",
    "        endpoint=\"/v1/chat/completions\",\n",
    "        completion_window=\"24h\",\n",
    "        metadata={\n",
    "            \"description\": f\"Processing batch {i+1} of {len(batch_files)} with {50} comments for Babylotse\"\n",
    "        },\n",
    "    )\n",
    "\n",
    "    batch_jobs.append(batch_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"batch/batch_jobs.pkl\", \"wb\") as f:\n",
    "    pickle.dump(batch_jobs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"batch/batch_jobs.pkl\", \"rb\") as f:\n",
    "    batch_jobs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, batch_job in enumerate(batch_jobs):\n",
    "    print(i, client.batches.retrieve(batch_job.id).status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only necessary if you want to wait \"live\", otherwise you can just use the code above to check the status on bulk as it can take up to 24 hours\n",
    "while True:\n",
    "    batch_info = client.batches.retrieve(batch_job.id)\n",
    "    print(batch_info.status)\n",
    "    if batch_info.status == \"completed\":\n",
    "        print(f\"Batch {i+1} finished.\")\n",
    "        break\n",
    "    if batch_info.status == \"failed\":\n",
    "        print(f\"Batch {i+1} failed.\")\n",
    "        print(batch_info.errors)\n",
    "        break\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for job in batch_jobs:\n",
    "    batch_info = client.batches.retrieve(job.id)\n",
    "    file_response = client.files.content(batch_info.output_file_id)\n",
    "\n",
    "    with open(f\"batch/{batch_info.output_file_id}.jsonl\", \"w\") as fhandle:\n",
    "        fhandle.write(file_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "files = list(Path(\"batch\").glob(\"file-*\"))\n",
    "\n",
    "pos_comments = []\n",
    "neg_comments = []\n",
    "for file in files:\n",
    "    with open(file) as f:\n",
    "        for line in f:\n",
    "            item = json.loads(line)\n",
    "            id, sentiment = item[\"custom_id\"].split(\"-\")\n",
    "\n",
    "            message = item[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"]\n",
    "            if sentiment == \"Positive\":\n",
    "                pos_comments.append((int(id), message))\n",
    "            elif sentiment == \"Negative\":\n",
    "                neg_comments.append((int(id), message))\n",
    "            else:\n",
    "                print(f\"Error! Don't support {sentiment}\")\n",
    "\n",
    "pos_comments = sorted(pos_comments, key=lambda x: x[0])\n",
    "neg_comments = sorted(neg_comments, key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pos_comments), len(neg_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_comments[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"artifacts/pos_results.pkl\", \"wb\") as f:\n",
    "    pickle.dump(pos_comments, f)\n",
    "\n",
    "with open(\"artifacts/neg_results.pkl\", \"wb\") as f:\n",
    "    pickle.dump(neg_comments, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
